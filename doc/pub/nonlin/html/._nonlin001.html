<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="description" content="Solving nonlinear ODE and PDE problems">
<meta name="keywords" content="linearization explicit time integration,linearization,Picard iteration,successive substitutions,fixed-point iteration,linearization Picard iteration,linearization successive substitutions,linearization fixed-point iteration,stopping criteria (nonlinear problems),single Picard iteration technique,relaxation (nonlinear equations),stopping criteria (nonlinear problems),continuation method,online rendering of LaTeX formulas,continuation method,group finite element method,product approximation technique">

<title>Solving nonlinear ODE and PDE problems</title>

<!-- Bootstrap style: bootswatch_journal -->
<link href="http://netdna.bootstrapcdn.com/bootswatch/3.1.1/journal/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">
/* Let inline verbatim have the same color as the surroundings */
code { color: inherit; background-color: transparent; }

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
</style>


</head>

<!-- tocinfo
{'highest level': 1,
 'sections': [('Introduction of basic concepts',
               1,
               'nonlin:timediscrete:logistic',
               'nonlin:timediscrete:logistic'),
              ('Linear versus nonlinear equations', 2, None, '___sec1'),
              ('Algebraic equations', 3, None, '___sec2'),
              ('Differential equations', 3, None, '___sec3'),
              ('A simple model problem', 2, None, '___sec4'),
              ('Linearization by explicit time discretization',
               2,
               'nonlin:timediscrete:logistic:FE',
               'nonlin:timediscrete:logistic:FE'),
              ('Exact solution of nonlinear algebraic equations',
               2,
               'nonlin:timediscrete:logistic:roots',
               'nonlin:timediscrete:logistic:roots'),
              ('Linearization', 2, None, '___sec7'),
              ('Picard iteration',
               2,
               'nonlin:timediscrete:logistic:Picard',
               'nonlin:timediscrete:logistic:Picard'),
              ('Stopping criteria', 3, None, '___sec9'),
              ('A single Picard iteration', 3, None, '___sec10'),
              ('Linearization by a geometric mean',
               2,
               'nonlin:timediscrete:logistic:geometric:mean',
               'nonlin:timediscrete:logistic:geometric:mean'),
              ("Newton's method",
               2,
               'nonlin:timediscrete:logistic:Newton',
               'nonlin:timediscrete:logistic:Newton'),
              ('Relaxation',
               2,
               'nonlin:timediscrete:logistic:relaxation',
               'nonlin:timediscrete:logistic:relaxation'),
              ('Implementation and experiments',
               2,
               'nonlin:timediscrete:logistic:impl',
               'nonlin:timediscrete:logistic:impl'),
              ('Generalization to a general nonlinear ODE',
               2,
               'nonlin:ode:generic',
               'nonlin:ode:generic'),
              ('Explicit time discretization', 3, None, '___sec16'),
              ('Backward Euler discretization', 3, None, '___sec17'),
              ('Crank-Nicolson discretization', 3, None, '___sec18'),
              ('Systems of ODEs',
               2,
               'nonlin:ode:generic:sys:pendulum',
               'nonlin:ode:generic:sys:pendulum'),
              ('Example', 3, None, '___sec20'),
              ('Systems of nonlinear algebraic equations',
               1,
               'nonlin:systems:alg',
               'nonlin:systems:alg'),
              ('Picard iteration',
               2,
               'nonlin:systems:alg:Picard',
               'nonlin:systems:alg:Picard'),
              ("Newton's method",
               2,
               'nonlin:systems:alg:Newton',
               'nonlin:systems:alg:Newton'),
              ('Stopping criteria',
               2,
               'nonlin:systems:alg:terminate',
               'nonlin:systems:alg:terminate'),
              ('Example: A nonlinear ODE model from epidemiology',
               2,
               'nonlin:systems:alg:SI',
               'nonlin:systems:alg:SI'),
              ('Implicit time discretization', 3, None, '___sec26'),
              ('A Picard iteration', 3, None, '___sec27'),
              ("Newton's method", 3, None, '___sec28'),
              ('Linearization at the differential equation level',
               1,
               'nonlin:pdelevel',
               'nonlin:pdelevel'),
              ('Explicit time integration',
               2,
               'nonlin:pdelevel:explicit',
               'nonlin:pdelevel:explicit'),
              ('Backward Euler scheme and Picard iteration',
               2,
               'nonlin:pdelevel:Picard',
               'nonlin:pdelevel:Picard'),
              ("Backward Euler scheme and Newton's method",
               2,
               'nonlin:pdelevel:Newton',
               'nonlin:pdelevel:Newton'),
              ('Linearization via Taylor expansions', 3, None, '___sec33'),
              ('Similarity with Picard iteration', 3, None, '___sec34'),
              ('Implementation', 3, None, '___sec35'),
              ('Derivation with alternative notation', 3, None, '___sec36'),
              ('Crank-Nicolson discretization',
               2,
               'nonlin:pdelevel:Picard:CN',
               'nonlin:pdelevel:Picard:CN'),
              ('Discretization of 1D stationary nonlinear differential equations',
               1,
               'nonlin:alglevel:1D',
               'nonlin:alglevel:1D'),
              ('Finite difference discretization',
               2,
               'nonlin:alglevel:1D:fd',
               'nonlin:alglevel:1D:fd'),
              ('Solution of algebraic equations', 2, None, '___sec40'),
              ('The structure of the equation system', 3, None, '___sec41'),
              ('Picard iteration', 3, None, '___sec42'),
              ('Mesh with two cells', 3, None, '___sec43'),
              ("Newton's method", 3, None, '___sec44'),
              ('Galerkin-type discretization',
               2,
               'nonlin:alglevel:1D:fe',
               'nonlin:alglevel:1D:fe'),
              ('Fundamental integration problem', 3, None, '___sec46'),
              ('Picard iteration defined from the variational form',
               2,
               'nonlin:alglevel:1D:fe:Picard',
               'nonlin:alglevel:1D:fe:Picard'),
              ("Newton's method defined from the variational form",
               2,
               'nonlin:alglevel:1D:fe:Newton',
               'nonlin:alglevel:1D:fe:Newton'),
              ('Dirichlet conditions', 3, None, '___sec49'),
              ('Multi-dimensional PDE problems', 1, None, '___sec50'),
              ('Finite element discretization',
               2,
               'nonlin:alglevel:dD:fe',
               'nonlin:alglevel:dD:fe'),
              ('Non-homogeneous Neumann conditions', 3, None, '___sec52'),
              ('Robin conditions', 3, None, '___sec53'),
              ('Finite difference discretization',
               2,
               'nonlin:alglevel:dD:fd',
               'nonlin:alglevel:dD:fd'),
              ('Picard iteration', 3, None, '___sec55'),
              ("Newton's method", 3, None, '___sec56'),
              ('Continuation methods', 2, None, '___sec57'),
              ('Exercises', 1, 'nonlin:exer', 'nonlin:exer'),
              ('Problem 1: Determine if equations are nonlinear or not',
               2,
               'nonlin:exer:lin:vs:nonlin',
               'nonlin:exer:lin:vs:nonlin'),
              ('Exercise 2: Derive and investigate a generalized logistic model',
               2,
               'nonlin:exer:logistic:gen',
               'nonlin:exer:logistic:gen'),
              ("Problem 3: Experience the behavior of Newton's method",
               2,
               'nonlin:exer:Newton:problems1',
               'nonlin:exer:Newton:problems1'),
              ('Problem 4: Compute the Jacobian of a $2\\times 2$ system',
               2,
               'nonlin:exer:vib:Jacobian',
               'nonlin:exer:vib:Jacobian'),
              ('Problem 5: Solve nonlinear equations arising from a vibration ODE',
               2,
               'nonlin:exer:vib:geometric:mean',
               'nonlin:exer:vib:geometric:mean'),
              ('Exercise 6: Find the truncation error of arithmetic mean of products',
               2,
               'nonlin:exer:products:arith:mean',
               'nonlin:exer:products:arith:mean'),
              ("Problem 7: Newton's method for linear problems",
               2,
               'nonlin:exer:Newton:linear',
               'nonlin:exer:Newton:linear'),
              ('Exercise 8: Discretize a 1D problem with a nonlinear coefficient',
               2,
               'nonlin:exer:1D:1pu2:fem',
               'nonlin:exer:1D:1pu2:fem'),
              ('Exercise 9: Linearize a 1D problem with a nonlinear coefficient',
               2,
               'nonlin:exer:1D:1pu2:PicardNewton',
               'nonlin:exer:1D:1pu2:PicardNewton'),
              ('Problem 10: Finite differences for the 1D Bratu problem',
               2,
               'nonlin:exer:1D:fu:discretize:fd',
               'nonlin:exer:1D:fu:discretize:fd'),
              ('Problem 11: Integrate functions of finite element expansions',
               2,
               'nonlin:exer:fu:fem:int',
               'nonlin:exer:fu:fem:int'),
              ('Problem 12: Finite elements for the 1D Bratu problem',
               2,
               'nonlin:exer:1D:fu:discretize:fe',
               'nonlin:exer:1D:fu:discretize:fe'),
              ('Exercise 13: Discretize a nonlinear 1D heat conduction PDE by finite differences',
               2,
               'nonlin:exer:1D:heat:nonlinear:fdm',
               'nonlin:exer:1D:heat:nonlinear:fdm'),
              ('Exercise 14: Use different symbols for different approximations of the solution',
               2,
               'nonlin:exer:dD:nonlinear:usymbols',
               'nonlin:exer:dD:nonlinear:usymbols'),
              ('Exercise 15: Derive Picard and Newton systems from a variational form',
               2,
               'nonlin:exer:dD:heat:nonlinear:c:a',
               'nonlin:exer:dD:heat:nonlinear:c:a'),
              ('Exercise 16: Derive algebraic equations for nonlinear 1D heat conduction',
               2,
               'nonlin:exer:1D:heat:nonlinear:c:a',
               'nonlin:exer:1D:heat:nonlinear:c:a'),
              ('Exercise 17: Differentiate a highly nonlinear term',
               2,
               'nonlin:exer:grad:pow:term',
               'nonlin:exer:grad:pow:term'),
              ('Exercise 18: Crank-Nicolson for a nonlinear 3D diffusion equation',
               2,
               'nonlin:exer:2D:heat:nonlinear:fd',
               'nonlin:exer:2D:heat:nonlinear:fd'),
              ('Exercise 19: Find the sparsity of the Jacobian',
               2,
               'nonlin:exer:sparsity:Jacobian',
               'nonlin:exer:sparsity:Jacobian'),
              ('Problem 20: Investigate a 1D problem with a continuation method',
               2,
               'nonlin:exer:continuation:1DnNflow',
               'nonlin:exer:continuation:1DnNflow'),
              ('Bibliography', 1, None, '___sec79'),
              ('Appendix: Symbolic nonlinear finite element equations',
               1,
               'nonlin:app:fem_vs_fdm',
               'nonlin:app:fem_vs_fdm'),
              ('Finite element basis functions',
               2,
               'nonlin:alglevel:1D:fe_basis',
               'nonlin:alglevel:1D:fe_basis'),
              ('The group finite element method',
               2,
               'nonlin:alglevel:1D:fe:group',
               'nonlin:alglevel:1D:fe:group'),
              ('Finite element approximation of functions of $u$',
               3,
               None,
               '___sec83'),
              ('Simplified problem', 3, None, '___sec84'),
              ('Integrating nonlinear functions', 3, None, '___sec85'),
              ('Application of the group finite element method',
               3,
               None,
               '___sec86'),
              ('Numerical integration of nonlinear terms by hand',
               2,
               'nonlin:alglevel:1D:fe:f',
               'nonlin:alglevel:1D:fe:f'),
              ('Finite element discretization of a variable coefficient Laplace term',
               2,
               'nonlin:alglevel:1D:fe:Laplace',
               'nonlin:alglevel:1D:fe:Laplace'),
              ('Group finite element method', 3, None, '___sec89'),
              ('Numerical integration at the nodes', 3, None, '___sec90')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript"
 src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<!-- newcommands_keep.tex -->
$$
\newcommand{\half}{\frac{1}{2}}
\newcommand{\tp}{\thinspace .}
\newcommand{\uex}{{u_{\small\mbox{e}}}}
\newcommand{\Oof}[1]{\mathcal{O}(#1)}
\newcommand{\x}{\boldsymbol{x}}
\renewcommand{\u}{\boldsymbol{u}}
\newcommand{\dfc}{\alpha}  % diffusion coefficient
\newcommand{\Ix}{\mathcal{I}_x}
\newcommand{\Iy}{\mathcal{I}_y}
\newcommand{\If}{\mathcal{I}_s}     % for FEM
\newcommand{\Ifd}{{I_d}}  % for FEM
\newcommand{\Ifb}{{I_b}}  % for FEM
\newcommand{\sequencei}[1]{\left\{ {#1}_i \right\}_{i\in\If}}
\newcommand{\basphi}{\varphi}
\newcommand{\baspsi}{\psi}
\newcommand{\refphi}{\tilde\basphi}
\newcommand{\xno}[1]{x_{#1}}
\newcommand{\dX}{\, \mathrm{d}X}
\newcommand{\dx}{\, \mathrm{d}x}
\newcommand{\ds}{\, \mathrm{d}s}
$$




    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="nonlin.html">Solving nonlinear ODE and PDE problems</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="#nonlin:timediscrete:logistic" style="font-size: 80%;"><b>Introduction of basic concepts</b></a></li>
     <!-- navigation toc: --> <li><a href="#___sec1" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Linear versus nonlinear equations</a></li>
     <!-- navigation toc: --> <li><a href="#___sec2" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Algebraic equations</a></li>
     <!-- navigation toc: --> <li><a href="#___sec3" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Differential equations</a></li>
     <!-- navigation toc: --> <li><a href="#___sec4" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;A simple model problem</a></li>
     <!-- navigation toc: --> <li><a href="#nonlin:timediscrete:logistic:FE" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Linearization by explicit time discretization</a></li>
     <!-- navigation toc: --> <li><a href="#nonlin:timediscrete:logistic:roots" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exact solution of nonlinear algebraic equations</a></li>
     <!-- navigation toc: --> <li><a href="#___sec7" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Linearization</a></li>
     <!-- navigation toc: --> <li><a href="#nonlin:timediscrete:logistic:Picard" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Picard iteration</a></li>
     <!-- navigation toc: --> <li><a href="#___sec9" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stopping criteria</a></li>
     <!-- navigation toc: --> <li><a href="#___sec10" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A single Picard iteration</a></li>
     <!-- navigation toc: --> <li><a href="#nonlin:timediscrete:logistic:geometric:mean" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Linearization by a geometric mean</a></li>
     <!-- navigation toc: --> <li><a href="#nonlin:timediscrete:logistic:Newton" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Newton's method</a></li>
     <!-- navigation toc: --> <li><a href="#nonlin:timediscrete:logistic:relaxation" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Relaxation</a></li>
     <!-- navigation toc: --> <li><a href="#nonlin:timediscrete:logistic:impl" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Implementation and experiments</a></li>
     <!-- navigation toc: --> <li><a href="#nonlin:ode:generic" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Generalization to a general nonlinear ODE</a></li>
     <!-- navigation toc: --> <li><a href="#___sec16" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Explicit time discretization</a></li>
     <!-- navigation toc: --> <li><a href="#___sec17" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Backward Euler discretization</a></li>
     <!-- navigation toc: --> <li><a href="#___sec18" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Crank-Nicolson discretization</a></li>
     <!-- navigation toc: --> <li><a href="#nonlin:ode:generic:sys:pendulum" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Systems of ODEs</a></li>
     <!-- navigation toc: --> <li><a href="#___sec20" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Example</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin002.html#nonlin:systems:alg" style="font-size: 80%;"><b>Systems of nonlinear algebraic equations</b></a></li>
     <!-- navigation toc: --> <li><a href="._nonlin002.html#nonlin:systems:alg:Picard" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Picard iteration</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin002.html#nonlin:systems:alg:Newton" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Newton's method</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin002.html#nonlin:systems:alg:terminate" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Stopping criteria</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin002.html#nonlin:systems:alg:SI" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Example: A nonlinear ODE model from epidemiology</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin002.html#___sec26" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Implicit time discretization</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin002.html#___sec27" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A Picard iteration</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin002.html#___sec28" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Newton's method</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin003.html#nonlin:pdelevel" style="font-size: 80%;"><b>Linearization at the differential equation level</b></a></li>
     <!-- navigation toc: --> <li><a href="._nonlin003.html#nonlin:pdelevel:explicit" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Explicit time integration</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin003.html#nonlin:pdelevel:Picard" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Backward Euler scheme and Picard iteration</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin003.html#nonlin:pdelevel:Newton" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Backward Euler scheme and Newton's method</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin003.html#___sec33" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Linearization via Taylor expansions</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin003.html#___sec34" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Similarity with Picard iteration</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin003.html#___sec35" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Implementation</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin003.html#___sec36" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Derivation with alternative notation</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin003.html#nonlin:pdelevel:Picard:CN" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Crank-Nicolson discretization</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin004.html#nonlin:alglevel:1D" style="font-size: 80%;"><b>Discretization of 1D stationary nonlinear differential equations</b></a></li>
     <!-- navigation toc: --> <li><a href="._nonlin004.html#nonlin:alglevel:1D:fd" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Finite difference discretization</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin004.html#___sec40" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Solution of algebraic equations</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin004.html#___sec41" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The structure of the equation system</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin004.html#___sec42" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Picard iteration</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin004.html#___sec43" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mesh with two cells</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin004.html#___sec44" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Newton's method</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin004.html#nonlin:alglevel:1D:fe" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Galerkin-type discretization</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin004.html#___sec46" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fundamental integration problem</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin004.html#nonlin:alglevel:1D:fe:Picard" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Picard iteration defined from the variational form</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin004.html#nonlin:alglevel:1D:fe:Newton" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Newton's method defined from the variational form</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin004.html#___sec49" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dirichlet conditions</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin005.html#___sec50" style="font-size: 80%;"><b>Multi-dimensional PDE problems</b></a></li>
     <!-- navigation toc: --> <li><a href="._nonlin005.html#nonlin:alglevel:dD:fe" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Finite element discretization</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin005.html#___sec52" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Non-homogeneous Neumann conditions</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin005.html#___sec53" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Robin conditions</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin005.html#nonlin:alglevel:dD:fd" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Finite difference discretization</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin005.html#___sec55" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Picard iteration</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin005.html#___sec56" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Newton's method</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin005.html#___sec57" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Continuation methods</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer" style="font-size: 80%;"><b>Exercises</b></a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:lin:vs:nonlin" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Problem 1: Determine if equations are nonlinear or not</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:logistic:gen" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 2: Derive and investigate a generalized logistic model</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:Newton:problems1" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Problem 3: Experience the behavior of Newton's method</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:vib:Jacobian" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Problem 4: Compute the Jacobian of a \( 2\times 2 \) system</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:vib:geometric:mean" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Problem 5: Solve nonlinear equations arising from a vibration ODE</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:products:arith:mean" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 6: Find the truncation error of arithmetic mean of products</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:Newton:linear" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Problem 7: Newton's method for linear problems</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:1D:1pu2:fem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 8: Discretize a 1D problem with a nonlinear coefficient</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:1D:1pu2:PicardNewton" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 9: Linearize a 1D problem with a nonlinear coefficient</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:1D:fu:discretize:fd" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Problem 10: Finite differences for the 1D Bratu problem</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:fu:fem:int" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Problem 11: Integrate functions of finite element expansions</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:1D:fu:discretize:fe" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Problem 12: Finite elements for the 1D Bratu problem</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:1D:heat:nonlinear:fdm" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 13: Discretize a nonlinear 1D heat conduction PDE by finite differences</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:dD:nonlinear:usymbols" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 14: Use different symbols for different approximations of the solution</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:dD:heat:nonlinear:c:a" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 15: Derive Picard and Newton systems from a variational form</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:1D:heat:nonlinear:c:a" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 16: Derive algebraic equations for nonlinear 1D heat conduction</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:grad:pow:term" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 17: Differentiate a highly nonlinear term</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:2D:heat:nonlinear:fd" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 18: Crank-Nicolson for a nonlinear 3D diffusion equation</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:sparsity:Jacobian" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 19: Find the sparsity of the Jacobian</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#nonlin:exer:continuation:1DnNflow" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Problem 20: Investigate a 1D problem with a continuation method</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin006.html#___sec79" style="font-size: 80%;"><b>Bibliography</b></a></li>
     <!-- navigation toc: --> <li><a href="._nonlin007.html#nonlin:app:fem_vs_fdm" style="font-size: 80%;"><b>Appendix: Symbolic nonlinear finite element equations</b></a></li>
     <!-- navigation toc: --> <li><a href="._nonlin007.html#nonlin:alglevel:1D:fe_basis" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Finite element basis functions</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin007.html#nonlin:alglevel:1D:fe:group" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The group finite element method</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin007.html#___sec83" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Finite element approximation of functions of \( u \)</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin007.html#___sec84" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Simplified problem</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin007.html#___sec85" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Integrating nonlinear functions</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin007.html#___sec86" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Application of the group finite element method</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin007.html#nonlin:alglevel:1D:fe:f" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Numerical integration of nonlinear terms by hand</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin007.html#nonlin:alglevel:1D:fe:Laplace" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Finite element discretization of a variable coefficient Laplace term</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin007.html#___sec89" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Group finite element method</a></li>
     <!-- navigation toc: --> <li><a href="._nonlin007.html#___sec90" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Numerical integration at the nodes</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0001"></a>
<!-- !split -->

<h1 id="nonlin:timediscrete:logistic">Introduction of basic concepts</h1>

<h2 id="___sec1">Linear versus nonlinear equations </h2>

<h3 id="___sec2">Algebraic equations </h3>

<p>
A linear, scalar, algebraic equation in \( x \) has the form

$$ ax + b = 0,$$

for arbitrary real constants \( a \) and \( b \). The unknown is a number \( x \).
All other algebraic equations, e.g., \( x^2 + ax + b = 0 \), are nonlinear.
The typical feature in a nonlinear algebraic equation is that the unknown
appears in products with itself, like \( x^2 \) or \( e^x = 1 + x +\half x^2 +
\frac{1}{3!}x^3 + \cdots \).

<p>
We know how to solve a linear algebraic equation, \( x=-b/a \), but there are
no general methods for finding the exact solutions of
nonlinear algebraic equations, except for very special cases (quadratic
equations are a primary example). A nonlinear algebraic equation
may have no solution, one solution, or many solutions. The tools for
solving nonlinear algebraic equations are <em>iterative methods</em>, where
we construct a series of linear equations, which we know how to solve,
and hope that the solutions of the linear equations converge to the
solution of the nonlinear equation we want to solve.
Typical methods for nonlinear algebraic equations are
Newton's method, the Bisection method, and the Secant method.

<h3 id="___sec3">Differential equations </h3>

<p>
The unknown in a differential equation is a function and not a number.
In a linear differential equation, all terms involving the unknown functions
are linear in the unknown functions or their derivatives. Linear here means that
the unknown function, or a derivative of it, is multiplied by a number or
a known function. All other differential equations are non-linear.

<p>
The easiest way to see if an equation is nonlinear, is to spot nonlinear terms
where the unknown functions or their derivatives are multiplied by
each other. For example, in

$$ u^{\prime}(t) = -a(t)u(t) + b(t),$$

the terms involving the unknown function \( u \) are linear: \( u^{\prime} \) contains
the derivative of the unknown function multiplied by unity, and \( au \) contains
the unknown function multiplied by a known function.
However,
$$ u^{\prime}(t) = u(t)(1 - u(t)),$$

is nonlinear because of the term \( -u^2 \) where the unknown function is
multiplied by itself. Also

$$ \frac{\partial u}{\partial t} + u\frac{\partial u}{\partial x} = 0,$$

is nonlinear because of the term \( uu_x \) where the unknown
function appears in a product with itself or one if its derivatives.
(Note here that we use different notations for derivatives: \( u^{\prime} \)
or \( du/dt \) for a function \( u(t) \) of one variable,
\( \frac{\partial u}{\partial t} \) or \( u_t \) for a function of more than one
variable.)

<p>
Another example of a nonlinear equation is

$$ u^{\prime\prime} + \sin(u) =0,$$

because \( \sin(u) \) contains products of \( u \) if we expand the function in
a Taylor series:

$$ \sin(u) = u - \frac{1}{3} u^3 + \ldots$$

<p>
<div class="alert alert-block alert-success alert-text-normal"><b>Mathematical proof of linearity.</b>
To really prove mathematically that some differential equation
in an unknown \( u \) is linear,
show for each term \( T(u) \) that with \( u = au_1 + bu_2 \) for
constants \( a \) and \( b \),

$$ T(au_1 + bu_2) = aT(u_1) + bT(u_2)\tp $$

<p>
For example, the term \( T(u) = (\sin^2 t)u'(t) \) is linear because

$$
\begin{align*}
T(au_1 + bu_2) &= (\sin^2 t)(au_1(t) + b u_2(t))\\ 
& = a(\sin^2 t)u_1(t) + b(\sin^2 t)u_2(t)\\ 
& =aT(u_1) + bT(u_2)\tp
\end{align*}
$$

However, \( T(u)=\sin u \) is nonlinear because

$$ T(au_1 + bu_2) = \sin (au_1 + bu_2) \neq a\sin u_1 + b\sin u_2\tp$$
</div>


<h2 id="___sec4">A simple model problem </h2>

<p>
A series of forthcoming examples will explain how to tackle
nonlinear differential equations with various techniques.
We start with the (scaled) logistic equation as model problem:

$$
\begin{equation}
u^{\prime}(t) = u(t)(1 - u(t)) \tp
\tag{1}
\end{equation}
$$

This is a nonlinear ordinary differential equation (ODE)
which will be solved by
different strategies in the following.
Depending on the chosen
time discretization of <a href="#mjx-eqn-1">(1)</a>,
the mathematical problem to be solved at every time level will
either be a linear algebraic equation or a nonlinear
algebraic equation.
In the former case, the time discretization method transforms
the nonlinear ODE into linear subproblems at each time level, and
the solution is straightforward to find since linear algebraic equations
are easy to solve. However,
when the time discretization leads to nonlinear algebraic equations, we
cannot (except in very rare cases) solve these without turning to
approximate, iterative solution methods.

<p>
The next subsections introduce various methods
for solving nonlinear differential equations,
using <a href="#mjx-eqn-1">(1)</a> as model. We shall go through
the following set cases:

<ul>
 <li> explicit time discretization methods (with no need to
   solve nonlinear algebraic equations)</li>
 <li> implicit Backward Euler discretization, leading to nonlinear
   algebraic equations solved by</li>

<ul>
  <li> an exact analytical technique</li>
  <li> Picard iteration based on manual linearization</li>
  <li> a single Picard step</li>
  <li> Newton's method</li>
</ul>

 <li> implicit Crank-Nicolson discretization and linearization
   via a geometric mean formula</li>
</ul>

Thereafter, we compare the performance of the various approaches. Despite
the simplicity of <a href="#mjx-eqn-1">(1)</a>, the conclusions
reveal typical features of the various methods in much more complicated
nonlinear PDE problems.

<h2 id="nonlin:timediscrete:logistic:FE">Linearization by explicit time discretization</h2>

<p>
Time discretization methods are divided into explicit and implicit
methods. Explicit methods lead to a closed-form formula for
finding new values of the unknowns, while implicit methods give
a linear or nonlinear system of equations that couples (all) the
unknowns at a new time level. Here we shall demonstrate that
explicit methods constitute an efficient way to deal with nonlinear
differential equations.

<p>
The Forward Euler
method is an explicit method. When applied to
<a href="#mjx-eqn-1">(1)</a>, sampled at \( t=t_n \), it results in

$$ \frac{u^{n+1} - u^n}{\Delta t} = u^n(1 - u^n),$$

which is a <em>linear</em> algebraic
equation for the unknown value \( u^{n+1} \) that we can easily solve:

$$ u^{n+1} = u^n + \Delta t\,u^n(1 - u^n)\tp$$

The nonlinearity in the original equation poses in this case no difficulty
in the discrete algebraic equation.
Any other explicit scheme in time will also give only linear
algebraic equations
to solve. For example, a typical 2nd-order Runge-Kutta method
for <a href="#mjx-eqn-1">(1)</a> leads to the following
formulas:

$$
\begin{align*}
u^* &= u^n + \Delta t u^n(1 - u^n),\\ 
u^{n+1} &= u^n + \Delta t \half \left(
u^n(1 - u^n) + u^*(1 - u^*))
\right)\tp
\end{align*}
$$

The first step is linear in the unknown \( u^* \). Then \( u^* \) is
known in the next step, which is linear in the unknown \( u^{n+1} \) .

<h2 id="nonlin:timediscrete:logistic:roots">Exact solution of nonlinear algebraic equations</h2>

<p>
Switching to a Backward Euler scheme for
<a href="#mjx-eqn-1">(1)</a>,

$$
\begin{equation}
\frac{u^{n} - u^{n-1}}{\Delta t} = u^n(1 - u^n),
\tag{2}
\end{equation}
$$

results in a nonlinear algebraic equation for the unknown value \( u^n \).
The equation is of quadratic type:

$$ \Delta t (u^n)^2 + (1-\Delta t)u^n - u^{n-1} = 0, $$

and may be solved exactly by the well-known formula for such equations.
Before we do so, however, we will
introduce a shorter, and often cleaner, notation for
nonlinear algebraic equations at a given time level. The notation is
inspired by the natural notation (i.e., variable names) used in a
program, especially in more advanced partial differential equation
problems. The unknown in the algebraic equation is denoted by \( u \),
while \( u^{(1)} \) is the value of the unknown at the previous time level
(in general, \( u^{(\ell)} \) is the value of the unknown \( \ell \) levels
back in time). The notation will be frequently used in later
sections. What is meant by \( u \) should be evident from the context: \( u \)
may be 1) the exact solution of the ODE/PDE problem,
2) the numerical approximation to the exact solution, or 3) the unknown
solution at a certain time level.

<p>
The quadratic equation for the unknown \( u^n \) in
<a href="#mjx-eqn-2">(2)</a> can, with the new
notation, be written

$$
\begin{equation}
F(u) = \Delta t u^2 + (1-\Delta t)u - u^{(1)} = 0\tp
\tag{3}
\end{equation}
$$

The solution is readily found to be

$$
\begin{equation}
u = \frac{1}{2\Delta t}
\left(-1+\Delta t \pm \sqrt{(1-\Delta t)^2 + 4\Delta t u^{(1)}}\right)
\tp
\tag{4}
\end{equation}
$$

<p>
Now we encounter a fundamental challenge with nonlinear
algebraic equations:
the equation may have more than one solution. How do we pick the right
solution? This is in general a hard problem.
In the present simple case, however, we can analyze the roots mathematically
and provide an answer. The idea is to expand the roots
in a series in \( \Delta t \) and truncate after the linear term since
the Backward Euler scheme will introduce an error proportional to
\( \Delta t \) anyway. Using <code>sympy</code> we find the following Taylor series
expansions of the roots:

<p>

<!-- code=python (!bc pyshell) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span style="color: #666666">&gt;&gt;&gt;</span> <span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">sympy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">sym</span>
<span style="color: #666666">&gt;&gt;&gt;</span> dt, u_1, u <span style="color: #666666">=</span> sym<span style="color: #666666">.</span>symbols(<span style="color: #BA2121">&#39;dt u_1 u&#39;</span>)
<span style="color: #666666">&gt;&gt;&gt;</span> r1, r2 <span style="color: #666666">=</span> sym<span style="color: #666666">.</span>solve(dt<span style="color: #666666">*</span>u<span style="color: #666666">**2</span> <span style="color: #666666">+</span> (<span style="color: #666666">1-</span>dt)<span style="color: #666666">*</span>u <span style="color: #666666">-</span> u_1, u)  <span style="color: #408080; font-style: italic"># find roots</span>
<span style="color: #666666">&gt;&gt;&gt;</span> r1
(dt <span style="color: #666666">-</span> sqrt(dt<span style="color: #666666">**2</span> <span style="color: #666666">+</span> <span style="color: #666666">4*</span>dt<span style="color: #666666">*</span>u_1 <span style="color: #666666">-</span> <span style="color: #666666">2*</span>dt <span style="color: #666666">+</span> <span style="color: #666666">1</span>) <span style="color: #666666">-</span> <span style="color: #666666">1</span>)<span style="color: #666666">/</span>(<span style="color: #666666">2*</span>dt)
<span style="color: #666666">&gt;&gt;&gt;</span> r2
(dt <span style="color: #666666">+</span> sqrt(dt<span style="color: #666666">**2</span> <span style="color: #666666">+</span> <span style="color: #666666">4*</span>dt<span style="color: #666666">*</span>u_1 <span style="color: #666666">-</span> <span style="color: #666666">2*</span>dt <span style="color: #666666">+</span> <span style="color: #666666">1</span>) <span style="color: #666666">-</span> <span style="color: #666666">1</span>)<span style="color: #666666">/</span>(<span style="color: #666666">2*</span>dt)
<span style="color: #666666">&gt;&gt;&gt;</span> <span style="color: #008000; font-weight: bold">print</span> r1<span style="color: #666666">.</span>series(dt, <span style="color: #666666">0</span>, <span style="color: #666666">2</span>)    <span style="color: #408080; font-style: italic"># 2 terms in dt, around dt=0</span>
<span style="color: #666666">-1/</span>dt <span style="color: #666666">+</span> <span style="color: #666666">1</span> <span style="color: #666666">-</span> u_1 <span style="color: #666666">+</span> dt<span style="color: #666666">*</span>(u_1<span style="color: #666666">**2</span> <span style="color: #666666">-</span> u_1) <span style="color: #666666">+</span> O(dt<span style="color: #666666">**2</span>)
<span style="color: #666666">&gt;&gt;&gt;</span> <span style="color: #008000; font-weight: bold">print</span> r2<span style="color: #666666">.</span>series(dt, <span style="color: #666666">0</span>, <span style="color: #666666">2</span>)
u_1 <span style="color: #666666">+</span> dt<span style="color: #666666">*</span>(<span style="color: #666666">-</span>u_1<span style="color: #666666">**2</span> <span style="color: #666666">+</span> u_1) <span style="color: #666666">+</span> O(dt<span style="color: #666666">**2</span>)
</pre></div>
<p>
We see that the <code>r1</code> root, corresponding to
a minus sign in front of the square root in
<a href="#mjx-eqn-4">(4)</a>,
behaves as \( 1/\Delta t \) and will therefore
blow up as \( \Delta t\rightarrow 0 \)! Since we know that \( u \) takes on
finite values, actually it is less than or equal to 1,
only the <code>r2</code> root is of relevance in this case: as \( \Delta t\rightarrow 0 \),
\( u\rightarrow u^{(1)} \), which is the expected result.

<p>
For those who are not well experienced with approximating mathematical
formulas by series expansion, an alternative method of investigation
is simply to compute the limits of the two roots as \( \Delta t\rightarrow 0 \)
and see if a limit unreasonable:

<p>

<!-- code=python (!bc pyshell) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span style="color: #666666">&gt;&gt;&gt;</span> <span style="color: #008000; font-weight: bold">print</span> r1<span style="color: #666666">.</span>limit(dt, <span style="color: #666666">0</span>)
<span style="color: #666666">-</span>oo
<span style="color: #666666">&gt;&gt;&gt;</span> <span style="color: #008000; font-weight: bold">print</span> r2<span style="color: #666666">.</span>limit(dt, <span style="color: #666666">0</span>)
u_1
</pre></div>

<h2 id="___sec7">Linearization </h2>

<p>
When the time integration of an ODE results in a nonlinear algebraic
equation, we must normally find its solution by defining a sequence
of linear equations and hope that the solutions of these linear equations
converge to the desired solution of the nonlinear algebraic equation.
Usually, this means solving the linear equation repeatedly in an
iterative fashion.
Alternatively, the nonlinear equation can sometimes be approximated by one
linear equation, and consequently there is no need for iteration.

<p>
Constructing a linear equation from a nonlinear one requires
<em>linearization</em> of each nonlinear term. This can be done manually
as in Picard iteration, or fully algorithmically as in Newton's method.
Examples will best illustrate how to linearize nonlinear problems.

<h2 id="nonlin:timediscrete:logistic:Picard">Picard iteration</h2>

<p>
Let us write <a href="#mjx-eqn-3">(3)</a> in a
more compact form

$$ F(u) = au^2 + bu + c = 0,$$

with \( a=\Delta t \), \( b=1-\Delta t \), and \( c=-u^{(1)} \).
Let \( u^{-} \) be an available approximation of the unknown \( u \).
Then we can linearize the term \( u^2 \) simply by writing
\( u^{-}u \). The resulting equation, \( \hat F(u)=0 \), is now linear
and hence easy to solve:

$$ F(u)\approx\hat F(u) = au^{-}u + bu + c = 0\tp$$

Since the equation \( \hat F=0 \) is only approximate, the solution \( u \)
does not equal the exact solution \( \uex \) of the exact
equation \( F(\uex)=0 \), but we can hope that \( u \) is closer to
\( \uex \) than \( u^{-} \) is, and hence it makes sense to repeat the
procedure, i.e., set \( u^{-}=u \) and solve \( \hat F(u)=0 \) again.
There is no guarantee that \( u \) is closer to \( \uex \) than \( u^{-} \),
but this approach has proven to be effective in a wide range of
applications.

<p>
The idea of turning a nonlinear equation into a linear one by
using an approximation \( u^{-} \) of \( u \) in nonlinear terms is
a widely used approach that goes under many names:
<em>fixed-point iteration</em>, the method of <em>successive substitutions</em>,
<em>nonlinear Richardson iteration</em>, and <em>Picard iteration</em>.
We will stick to the latter name.

<p>
Picard iteration for solving the nonlinear equation
arising from the Backward Euler discretization of the logistic
equation can be written as

$$ u = -\frac{c}{au^{-} + b},\quad u^{-}\ \leftarrow\ u\tp$$

The \( \leftarrow \) symbols means assignment (we set \( u^{-} \) equal to
the value of \( u \)).
The iteration is started with the value of the unknown at the
previous time level: \( u^{-}=u^{(1)} \).

<p>
Some people prefer an explicit iteration counter as superscript
in the mathematical notation. Let \( u^k \) be the computed approximation
to the solution in iteration \( k \). In iteration \( k+1 \) we want
to solve

$$ au^k u^{k+1} + bu^{k+1} + c = 0\quad\Rightarrow\quad u^{k+1}
= -\frac{c}{au^k + b},\quad k=0,1,\ldots$$

Since we need to perform the iteration at every time level, the
time level counter is often also included (recall that \( c=-u^{n-1} \)):

$$ au^{n,k} u^{n,k+1} + bu^{n,k+1} - u^{n-1} = 0\quad\Rightarrow\quad u^{n,k+1}
= \frac{u^{n-1}}{au^{n,k} + b},\quad k=0,1,\ldots,$$

with the start value \( u^{n,0}=u^{n-1} \) and the final converged value
\( u^{n}=u^{n,k} \) for sufficiently large \( k \).

<p>
However, we will normally apply a mathematical notation in our
final formulas that is as close as possible to what we aim to write
in a computer code and then it becomes natural to use \( u \) and \( u^{-} \)
instead of \( u^{k+1} \) and \( u^k \) or \( u^{n,k+1} \) and \( u^{n,k} \).

<h3 id="___sec9">Stopping criteria </h3>

<p>
The iteration method can typically be terminated when the change
in the solution is smaller than a tolerance \( \epsilon_u \):

$$ |u - u^{-}| \leq\epsilon_u,$$

or when the residual in the equation is sufficiently small (\( \epsilon_r \)),
$$ |F(u)|= |au^2+bu + c| < \epsilon_r\tp$$

<h3 id="___sec10">A single Picard iteration </h3>

<p>
Instead of iterating until a stopping criterion is fulfilled, one may
iterate a specific number of times. Just one Picard iteration is
popular as this corresponds to the intuitive idea of approximating
a nonlinear term like \( (u^n)^2 \) by \( u^{n-1}u^n \). This follows
from the linearization \( u^{-}u^n \) and the initial choice of
\( u^{-}=u^{n-1} \) at time level \( t_n \). In other words, a single
Picard iteration corresponds to using the solution at
the previous time level to linearize
nonlinear terms. The resulting discretization
becomes (using proper values for \( a \), \( b \), and \( c \))

$$
\begin{equation}
\frac{u^{n} - u^{n-1}}{\Delta t} = u^n(1 - u^{n-1}),
\tag{5}
\end{equation}
$$

which is a linear algebraic equation in the unknown \( u^n \), and
therefore we can easily solve for \( u^n \), and there is no need
for any alternative notation.

<p>
We shall later refer to the strategy of taking one Picard step, or
equivalently, linearizing terms with use of the solution at the
previous time step, as the <em>Picard1</em> method. It is a widely used
approach in science and technology, but with some limitations if
\( \Delta t \) is not sufficiently small (as will be illustrated later).

<p>
<div class="alert alert-block alert-success alert-text-normal"><b>Notice.</b>

<p>
Equation <a href="#mjx-eqn-5">(5)</a> does not
correspond to a &quot;pure&quot; finite difference method where the equation
is sampled at a point and derivatives replaced by differences (because
the \( u^{n-1} \) term on the right-hand side must then be \( u^n \)). The
best interpretation of the scheme
<a href="#mjx-eqn-5">(5)</a> is a Backward Euler
difference combined with a single (perhaps insufficient) Picard
iteration at each time level, with the value at the previous time
level as start for the Picard iteration.

<p>
</div>


<h2 id="nonlin:timediscrete:logistic:geometric:mean">Linearization by a geometric mean</h2>

<p>
We consider now a Crank-Nicolson discretization of
<a href="#mjx-eqn-1">(1)</a>. This means that the
time derivative is approximated by a centered
difference,

$$ [D_t u = u(1-u)]^{n+\half},$$

written out as

$$
\begin{equation}
\frac{u^{n+1}-u^n}{\Delta t} = u^{n+\half} -
(u^{n+\half})^2\tp
\tag{6}
\end{equation}
$$

The term \( u^{n+\half} \) is normally approximated by an arithmetic
mean,

$$ u^{n+\half}\approx \half(u^n + u^{n+1}),$$

such that the scheme involves the unknown function only at the time levels
where we actually compute it.
The same arithmetic mean applied to the nonlinear term gives

$$ (u^{n+\half})^2\approx \frac{1}{4}(u^n + u^{n+1})^2,$$

which is nonlinear in the unknown \( u^{n+1} \).
However, using a <em>geometric mean</em> for \( (u^{n+\half})^2 \)
is a way of linearizing the nonlinear term in
<a href="#mjx-eqn-6">(6)</a>:

$$ (u^{n+\half})^2\approx u^nu^{n+1}\tp$$

Using an arithmetic mean on the linear \( u^{n+\frac{1}{2}} \) term in
<a href="#mjx-eqn-6">(6)</a> and a geometric
mean for the second term, results in a linearized equation for the
unknown \( u^{n+1} \):

$$ \frac{u^{n+1}-u^n}{\Delta t} =
\half(u^n + u^{n+1}) - u^nu^{n+1},$$

which can readily be solved:

$$
u^{n+1} = \frac{1 + \half\Delta t}{1+\Delta t u^n - \half\Delta t}
u^n\tp$$

This scheme can be coded directly, and since
there is no nonlinear algebraic equation to iterate over,
we skip the simplified notation with \( u \) for \( u^{n+1} \)
and \( u^{(1)} \) for \( u^n \). The technique with using
a geometric average is an example of transforming a nonlinear
algebraic equation to a linear one, without any need for iterations.

<p>
The geometric mean approximation is often very effective for
linearizing quadratic nonlinearities. Both the arithmetic and geometric mean
approximations have truncation errors of order \( \Delta t^2 \) and are
therefore compatible with the truncation error \( \Oof{\Delta t^2} \)
of the centered difference approximation for \( u^\prime \) in the Crank-Nicolson
method.

<p>
Applying the operator notation for the means and finite differences,
the linearized Crank-Nicolson scheme for the logistic equation can be
compactly expressed as

$$ [D_t u = \overline{u}^{t} - \overline{u^2}^{t,g}]^{n+\half}\tp$$

<p>
<div class="alert alert-block alert-success alert-text-normal"><b>Remark.</b>
If we use an arithmetic instead of a geometric mean
for the nonlinear term in
<a href="#mjx-eqn-6">(6)</a>,
we end up with a nonlinear term \( (u^{n+1})^2 \).
This term can be linearized as \( u^{-}u^{n+1} \) in a Picard iteration
approach and in particular as
\( u^nu^{n+1} \) in a Picard1 iteration approach.
The latter gives a scheme almost identical to the one arising from
a geometric mean (the difference in \( u^{n+1} \)
being \( \frac{1}{4}\Delta t u^n(u^{n+1}-u^n)\approx \frac{1}{4}\Delta t^2
u^\prime u \), i.e., a difference of \( \Oof{\Delta t^2} \)).
</div>


<h2 id="nonlin:timediscrete:logistic:Newton">Newton's method</h2>

<p>
The Backward Euler scheme <a href="#mjx-eqn-2">(2)</a>
for the logistic equation leads to a nonlinear algebraic equation
<a href="#mjx-eqn-3">(3)</a>. Now we write any nonlinear
algebraic equation in the general and compact form

$$ F(u) = 0\tp$$

Newton's method linearizes this equation by approximating \( F(u) \) with
its Taylor series expansion around a computed value \( u^{-} \)
and keeping only the linear part:

$$
\begin{align*}
F(u) &= F(u^{-}) + F^{\prime}(u^{-})(u - u^{-}) + {\half}F^{\prime\prime}(u^{-})(u-u^{-})^2
+\cdots\\ 
& \approx F(u^{-}) + F^{\prime}(u^{-})(u - u^{-}) = \hat F(u)\tp
\end{align*}
$$

The linear equation \( \hat F(u)=0 \) has the solution

$$ u = u^{-} - \frac{F(u^{-})}{F^{\prime}(u^{-})}\tp$$

Expressed with an iteration index in the unknown, Newton's method takes
on the more familiar mathematical form

$$ u^{k+1} = u^k - \frac{F(u^k)}{F^{\prime}(u^k)},\quad k=0,1,\ldots$$

<p>
It can be shown that the error in iteration \( k+1 \) of Newton's method is
the square of the error in iteration \( k \), a result referred to as
<em>quadratic convergence</em>. This means that for
small errors the method converges very fast, and in particular much
faster than Picard iteration and other iteration methods.
(The proof of this result is found in most textbooks on numerical analysis.)
However, the quadratic convergence appears only if \( u^k \) is sufficiently
close to the solution. Further away from the solution the method can
easily converge very slowly or diverge. The reader is encouraged to do
<a href="._nonlin006.html#nonlin:exer:Newton:problems1">Problem 3: Experience the behavior of Newton's method</a> to get a better understanding
for the behavior of the method.

<p>
Application of Newton's method to the logistic equation discretized
by the Backward Euler method is straightforward
as we have

$$ F(u) = au^2 + bu + c,\quad a=\Delta t,\ b = 1-\Delta t,\ c=-u^{(1)},$$

and then

$$ F^{\prime}(u) = 2au + b\tp$$

The iteration method becomes

$$
\begin{equation}
u = u^{-} - \frac{a(u^{-})^2 + bu^{-} + c}{2au^{-} + b},\quad
u^{-}\ \leftarrow u\tp
\tag{7}
\end{equation}
$$

At each time level, we start the iteration by setting \( u^{-}=u^{(1)} \).
Stopping criteria as listed for the Picard iteration can be used also
for Newton's method.

<p>
An alternative mathematical form, where we write out \( a \), \( b \), and \( c \),
and use a time level counter \( n \) and an iteration counter \( k \), takes
the form

$$
\begin{equation}
u^{n,k+1} = u^{n,k} -
\frac{\Delta t (u^{n,k})^2 + (1-\Delta t)u^{n,k} - u^{n-1}}
{2\Delta t u^{n,k} + 1 - \Delta t},\quad u^{n,0}=u^{n-1},\quad k=0,1,\ldots
\tag{8}
\end{equation}
$$

A program implementation is much closer to <a href="#mjx-eqn-7">(7)</a> than to <a href="#mjx-eqn-8">(8)</a>, but
the latter is better aligned with the established mathematical
notation used in the literature.

<h2 id="nonlin:timediscrete:logistic:relaxation">Relaxation</h2>

<p>
One iteration in Newton's method or
Picard iteration consists of solving a linear problem \( \hat F(u)=0 \).
Sometimes convergence problems arise because the new solution \( u \)
of \( \hat F(u)=0 \) is &quot;too far away&quot; from the previously computed
solution \( u^{-} \). A remedy is to introduce a relaxation, meaning that
we first solve \( \hat F(u^*)=0 \) for a suggested value \( u^* \) and
then we take \( u \) as a weighted mean of what we had, \( u^{-} \), and
what our linearized equation \( \hat F=0 \) suggests, \( u^* \):

$$ u = \omega u^* + (1-\omega) u^{-}\tp$$

The parameter \( \omega \)
is known as a <em>relaxation parameter</em>, and a choice \( \omega < 1 \)
may prevent divergent iterations.

<p>
Relaxation in Newton's method can be directly incorporated
in the basic iteration formula:

$$
\begin{equation}
u = u^{-} - \omega \frac{F(u^{-})}{F^{\prime}(u^{-})}\tp
\tag{9}
\end{equation}
$$

<h2 id="nonlin:timediscrete:logistic:impl">Implementation and experiments</h2>

<p>
The program <a href="http://tinyurl.com/nm5587k/nonlin/logistic.py" target="_self"><tt>logistic.py</tt></a> contains
implementations of all the methods described above.
Below is an extract of the file showing how the Picard and Newton
methods are implemented for a Backward Euler discretization of
the logistic equation.

<p>
<!-- @@@CODE src-nonlin/logistic.py fromto: def BE_logistic@def CN_logistic -->

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">BE_logistic</span>(u0, dt, Nt, choice<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Picard&#39;</span>,
                eps_r<span style="color: #666666">=1E-3</span>, omega<span style="color: #666666">=1</span>, max_iter<span style="color: #666666">=1000</span>):
    <span style="color: #008000; font-weight: bold">if</span> choice <span style="color: #666666">==</span> <span style="color: #BA2121">&#39;Picard1&#39;</span>:
        choice <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;Picard&#39;</span>
        max_iter <span style="color: #666666">=</span> <span style="color: #666666">1</span>

    u <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros(Nt<span style="color: #666666">+1</span>)
    iterations <span style="color: #666666">=</span> []
    u[<span style="color: #666666">0</span>] <span style="color: #666666">=</span> u0
    <span style="color: #008000; font-weight: bold">for</span> n <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #666666">1</span>, Nt<span style="color: #666666">+1</span>):
        a <span style="color: #666666">=</span> dt
        b <span style="color: #666666">=</span> <span style="color: #666666">1</span> <span style="color: #666666">-</span> dt
        c <span style="color: #666666">=</span> <span style="color: #666666">-</span>u[n<span style="color: #666666">-1</span>]

        <span style="color: #008000; font-weight: bold">if</span> choice <span style="color: #666666">==</span> <span style="color: #BA2121">&#39;Picard&#39;</span>:

            <span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">F</span>(u):
                <span style="color: #008000; font-weight: bold">return</span> a<span style="color: #666666">*</span>u<span style="color: #666666">**2</span> <span style="color: #666666">+</span> b<span style="color: #666666">*</span>u <span style="color: #666666">+</span> c

            u_ <span style="color: #666666">=</span> u[n<span style="color: #666666">-1</span>]
            k <span style="color: #666666">=</span> <span style="color: #666666">0</span>
            <span style="color: #008000; font-weight: bold">while</span> <span style="color: #008000">abs</span>(F(u_)) <span style="color: #666666">&gt;</span> eps_r <span style="color: #AA22FF; font-weight: bold">and</span> k <span style="color: #666666">&lt;</span> max_iter:
                u_ <span style="color: #666666">=</span> omega<span style="color: #666666">*</span>(<span style="color: #666666">-</span>c<span style="color: #666666">/</span>(a<span style="color: #666666">*</span>u_ <span style="color: #666666">+</span> b)) <span style="color: #666666">+</span> (<span style="color: #666666">1-</span>omega)<span style="color: #666666">*</span>u_
                k <span style="color: #666666">+=</span> <span style="color: #666666">1</span>
            u[n] <span style="color: #666666">=</span> u_
            iterations<span style="color: #666666">.</span>append(k)

        <span style="color: #008000; font-weight: bold">elif</span> choice <span style="color: #666666">==</span> <span style="color: #BA2121">&#39;Newton&#39;</span>:

            <span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">F</span>(u):
                <span style="color: #008000; font-weight: bold">return</span> a<span style="color: #666666">*</span>u<span style="color: #666666">**2</span> <span style="color: #666666">+</span> b<span style="color: #666666">*</span>u <span style="color: #666666">+</span> c

            <span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">dF</span>(u):
                <span style="color: #008000; font-weight: bold">return</span> <span style="color: #666666">2*</span>a<span style="color: #666666">*</span>u <span style="color: #666666">+</span> b

            u_ <span style="color: #666666">=</span> u[n<span style="color: #666666">-1</span>]
            k <span style="color: #666666">=</span> <span style="color: #666666">0</span>
            <span style="color: #008000; font-weight: bold">while</span> <span style="color: #008000">abs</span>(F(u_)) <span style="color: #666666">&gt;</span> eps_r <span style="color: #AA22FF; font-weight: bold">and</span> k <span style="color: #666666">&lt;</span> max_iter:
                u_ <span style="color: #666666">=</span> u_ <span style="color: #666666">-</span> F(u_)<span style="color: #666666">/</span>dF(u_)
                k <span style="color: #666666">+=</span> <span style="color: #666666">1</span>
            u[n] <span style="color: #666666">=</span> u_
            iterations<span style="color: #666666">.</span>append(k)
    <span style="color: #008000; font-weight: bold">return</span> u, iterations
</pre></div>
<p>
The Crank-Nicolson method utilizing a linearization based on the
geometric mean gives a simpler algorithm:

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">CN_logistic</span>(u0, dt, Nt):
    u <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros(Nt<span style="color: #666666">+1</span>)
    u[<span style="color: #666666">0</span>] <span style="color: #666666">=</span> u0
    <span style="color: #008000; font-weight: bold">for</span> n <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #666666">0</span>, Nt):
        u[n<span style="color: #666666">+1</span>] <span style="color: #666666">=</span> (<span style="color: #666666">1</span> <span style="color: #666666">+</span> <span style="color: #666666">0.5*</span>dt)<span style="color: #666666">/</span>(<span style="color: #666666">1</span> <span style="color: #666666">+</span> dt<span style="color: #666666">*</span>u[n] <span style="color: #666666">-</span> <span style="color: #666666">0.5*</span>dt)<span style="color: #666666">*</span>u[n]
    <span style="color: #008000; font-weight: bold">return</span> u
</pre></div>
<p>
We may run experiments with the model problem
<a href="#mjx-eqn-1">(1)</a> and the different strategies for
dealing with nonlinearities as described above. For a quite coarse
time resolution, \( \Delta t=0.9 \), use of a tolerance \( \epsilon_r=0.1 \)
in the stopping criterion introduces an iteration error, especially in
the Picard iterations, that is visibly much larger than the
time discretization error due to a large \( \Delta t \). This is illustrated
by comparing the upper two plots in
Figure <a href="#nonlin:timediscrete:logistic:impl:fig:u">1</a>. The one to
the right has a stricter tolerance \( \epsilon = 10^{-3} \), which leads
to all the curves corresponding to Picard and Newton iteration to be
on top of each other (and no changes can be visually observed by
reducing \( \epsilon_r \) further). The reason why Newton's method does
much better than Picard iteration in the upper left plot is that
Newton's method with one step comes far below the \( \epsilon_r \) tolerance,
while the Picard iteration needs on average 7 iterations to bring the
residual down to \( \epsilon_r=10^{-1} \), which gives insufficient
accuracy in the solution of the nonlinear equation. It is obvious
that the Picard1 method gives significant errors in addition to
the time discretization unless the time step is as small as in
the lower right plot.

<p>
The <em>BE exact</em> curve corresponds to using the exact solution of the
quadratic equation at each time level, so this curve is only affected
by the Backward Euler time discretization.  The <em>CN gm</em> curve
corresponds to the theoretically more accurate Crank-Nicolson
discretization, combined with a geometric mean for linearization.
This curve appears as more accurate, especially if we take the plot in
the lower right with a small \( \Delta t \) and an appropriately small
\( \epsilon_r \) value as the exact curve.

<p>
When it comes to the need for iterations, Figure
<a href="#nonlin:timediscrete:logistic:impl:fig:iter">2</a> displays the number of
iterations required at each time level for Newton's method and
Picard iteration. The smaller \( \Delta t \) is, the better starting value
we have for the iteration, and the faster the convergence is.
With \( \Delta t = 0.9 \) Picard iteration requires on average 32 iterations
per time step, but this number is dramatically reduced as \( \Delta t \)
is reduced.

<p>
However, introducing relaxation and a parameter \( \omega=0.8 \)
immediately reduces the average of 32 to 7, indicating that for the large
\( \Delta t=0.9 \), Picard iteration takes too long steps. An approximately optimal
value for \( \omega \) in this case is 0.5, which results in an average of only
2 iterations! Even more dramatic impact of \( \omega \) appears when
\( \Delta t = 1 \): Picard iteration does not convergence in 1000 iterations,
but \( \omega=0.5 \) again brings the average number of iterations down to 2.

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 1:  Impact of solution strategy and time step length on the solution. <div id="nonlin:timediscrete:logistic:impl:fig:u"></div> </p></center>
<p><img src="fig-nonlin/logistic_u.png" align="bottom" width=800></p>
</center>

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 2:  Comparison of the number of iterations at various time levels for Picard and Newton iteration. <div id="nonlin:timediscrete:logistic:impl:fig:iter"></div> </p></center>
<p><img src="fig-nonlin/logistic_iter.png" align="bottom" width=800></p>
</center>

<p>
<b>Remark.</b>
The simple Crank-Nicolson method with a geometric mean for the quadratic
nonlinearity gives visually more accurate solutions than the
Backward Euler discretization. Even with a tolerance of \( \epsilon_r=10^{-3} \),
all the methods for treating the nonlinearities in the Backward Euler
discretization give graphs that cannot be distinguished. So for
accuracy in this problem, the time discretization is much more crucial
than \( \epsilon_r \). Ideally, one should estimate the error in the
time discretization, as the solution progresses, and set \( \epsilon_r \)
accordingly.

<h2 id="nonlin:ode:generic">Generalization to a general nonlinear ODE</h2>

<p>
Let us see how the various methods in the previous sections
can be applied to the more generic model

$$
\begin{equation}
u^{\prime} = f(u, t),
\tag{10}
\end{equation}
$$

where \( f \) is a nonlinear function of \( u \).

<h3 id="___sec16">Explicit time discretization </h3>

<p>
Explicit ODE methods like the Forward Euler scheme, Runge-Kutta methods,
Adams-Bashforth methods all evaluate \( f \) at time levels where
\( u \) is already computed, so nonlinearities in \( f \) do not
pose any difficulties.

<h3 id="___sec17">Backward Euler discretization </h3>

<p>
Approximating \( u^{\prime} \) by a backward difference leads to a Backward Euler
scheme, which can be written as

$$ F(u^n) = u^{n} - \Delta t\, f(u^n, t_n) - u^{n-1}=0,$$

or alternatively

$$ F(u) = u - \Delta t\, f(u, t_n) - u^{(1)} = 0\tp$$

A simple Picard iteration, not knowing anything about the nonlinear
structure of \( f \), must approximate \( f(u,t_n) \) by \( f(u^{-},t_n) \):

$$ \hat F(u) = u - \Delta t\, f(u^{-},t_n) - u^{(1)}\tp$$

The iteration starts with \( u^{-}=u^{(1)} \) and proceeds with repeating

$$ u^* = \Delta t\, f(u^{-},t_n) + u^{(1)},\quad u = \omega u^* + (1-\omega)u^{-},
\quad u^{-}\ \leftarrow\ u,$$

until a stopping criterion is fulfilled.

<p>
<div class="alert alert-block alert-success alert-text-normal"><b>Explicit vs implicit treatment of nonlinear terms.</b>
Evaluating \( f \) for a known \( u^{-} \) is referred to as <em>explicit</em> treatment of
\( f \), while if \( f(u,t) \) has some structure, say \( f(u,t) = u^3 \), parts of
\( f \) can involve the known \( u \), as in the manual linearization
like \( (u^{-})^2u \), and then the treatment of \( f \) is &quot;more implicit&quot;
and &quot;less explicit&quot;. This terminology is inspired by time discretization
of \( u^{\prime}=f(u,t) \), where evaluating \( f \) for known \( u \) values gives
explicit schemes, while treating \( f \) or parts of \( f \) implicitly,
makes \( f \) contribute to the unknown terms in the equation at the new
time level.

<p>
Explicit treatment of \( f \) usually means stricter conditions on
\( \Delta t \) to achieve stability of time discretization schemes. The same
applies to iteration techniques for nonlinear algebraic equations: the &quot;less&quot;
we linearize \( f \) (i.e., the more we keep of \( u \) in the original formula),
the faster the convergence may be.

<p>
We may say that \( f(u,t)=u^3 \) is treated explicitly if we evaluate \( f \)
as \( (u^{-})^3 \), partially implicit if we linearize as \( (u^{-})^2u \)
and fully implicit if we represent \( f \) by \( u^3 \). (Of course, the
fully implicit representation will require further linearization,
but with \( f(u,t)=u^2 \) a fully implicit treatment is possible if
the resulting quadratic equation is solved with a formula.)

<p>
For the ODE \( u^{\prime}=-u^3 \) with \( f(u,t)=-u^3 \) and coarse
time resolution \( \Delta t = 0.4 \), Picard iteration with \( (u^{-})^2u \)
requires 8 iterations with \( \epsilon_r = 10^{-3} \) for the first
time step, while \( (u^{-})^3 \) leads to 22 iterations. After about 10
time steps both approaches are down to about 2 iterations per time
step, but this example shows a potential of treating \( f \) more
implicitly.

<p>
A trick to treat \( f \) implicitly in Picard iteration is to
evaluate it as \( f(u^{-},t)u/u^{-} \). For a polynomial \( f \), \( f(u,t)=u^m \),
this corresponds to \( (u^{-})^{m-1}u \). Sometimes this more implicit
treatment has no effect, as with \( f(u,t)=\exp(-u) \) and \( f(u,t)=\ln (1+u) \),
but with \( f(u,t)=\sin(2(u+1)) \), the \( f(u^{-},t)u/u^{-} \) trick
leads to 7, 9, and 11 iterations during the first three steps, while
\( f(u^{-},t) \) demands 17, 21, and 20 iterations.
(Experiments can be done with the code <a href="http://tinyurl.com/nm5587k/nonlin/ODE_Picard_tricks.py" target="_self"><tt>ODE_Picard_tricks.py</tt></a>.)
</div>


<p>
Newton's method applied to a Backward Euler discretization of
\( u^{\prime}=f(u,t) \)
requires the computation of the derivative

$$ F^{\prime}(u) = 1 - \Delta t\frac{\partial f}{\partial u}(u,t_n)\tp$$

Starting with the solution at the previous time level, \( u^{-}=u^{(1)} \),
we can just use the standard formula

$$
\begin{equation}
u = u^{-} - \omega \frac{F(u^{-})}{F^{\prime}(u^{-})}
= u^{-} - \omega \frac{u^{-} - \Delta t\, f(u^{-}, t_n) - u^{(1)}}{1 - \Delta t
\frac{\partial}{\partial u}f(u^{-},t_n)}
\tp
\tag{11}
\end{equation}
$$

<p>
<!-- The geometric mean trick cannot be used unless we know that \( f \) has -->
<!-- a special structure with quadratic expressions in \( u \). -->

<h3 id="___sec18">Crank-Nicolson discretization </h3>

<p>
The standard Crank-Nicolson scheme with arithmetic mean approximation of
\( f \) takes the form

$$ \frac{u^{n+1} - u^n}{\Delta t} = \half(f(u^{n+1}, t_{n+1})
+ f(u^n, t_n))\tp$$

We can write the scheme as a nonlinear algebraic equation

$$
\begin{equation}
F(u) = u - u^{(1)} - \Delta t{\half}f(u,t_{n+1}) -
\Delta t{\half}f(u^{(1)},t_{n}) = 0\tp
\tag{12}
\end{equation}
$$

A Picard iteration scheme must in general employ the linearization

$$ \hat F(u) = u - u^{(1)} - \Delta t{\half}f(u^{-},t_{n+1}) -
\Delta t{\half}f(u^{(1)},t_{n}),$$

while Newton's method can apply the general formula
<a href="#mjx-eqn-11">(11)</a> with \( F(u) \) given in
<a href="#mjx-eqn-12">(12)</a> and

$$ F^{\prime}(u)= 1 - \half\Delta t\frac{\partial f}{\partial u}(u,t_{n+1})\tp$$

<p>
<!-- What about pendulum sin(u) as u/u_ sin(u_)? Check in odespy if it -->
<!-- converges faster (should be able to store the no of Newton and -->
<!-- Picard iterations in the classes and poll afterwards). It the trick -->
<!-- pays off, describe it here. Can odespy be used here? That is, can we -->
<!-- provide the linearization? No...? -->

<h2 id="nonlin:ode:generic:sys:pendulum">Systems of ODEs</h2>

<p>
We may write a system of ODEs

$$
\begin{align*}
\frac{d}{dt}u_0(t) &= f_0(u_0(t),u_1(t),\ldots,u_N(t),t),\\ 
\frac{d}{dt}u_1(t) &= f_1(u_0(t),u_1(t),\ldots,u_N(t),t),\\ 
&\vdots\\ 
\frac{d}{dt}u_m(t) &= f_m(u_0(t),u_1(t),\ldots,u_N(t),t),
\end{align*}
$$

as

$$
\begin{equation}
u^{\prime} = f(u,t),\quad u(0)=U_0,
\tag{13}
\end{equation}
$$

if we interpret \( u \) as a vector \( u=(u_0(t),u_1(t),\ldots,u_N(t)) \)
and \( f \) as a vector function with components
\( (f_0(u,t),f_1(u,t),\ldots,f_N(u,t)) \).

<p>
Most solution methods for scalar ODEs, including
the Forward and Backward Euler schemes and the
Crank-Nicolson method, generalize in a
straightforward way to systems of ODEs simply by using vector
arithmetics instead of scalar arithmetics, which corresponds to
applying the scalar scheme to each component of the system.  For
example, here is a backward difference scheme applied to each
component,

$$
\begin{align*}
\frac{u_0^n- u_0^{n-1}}{\Delta t} &= f_0(u^n,t_n),\\ 
\frac{u_1^n- u_1^{n-1}}{\Delta t} &= f_1(u^n,t_n),\\ 
&\vdots\\ 
\frac{u_N^n- u_N^{n-1}}{\Delta t} &= f_N(u^n,t_n),
\end{align*}
$$

which can be written more compactly in vector form as

$$ \frac{u^n- u^{n-1}}{\Delta t} = f(u^n,t_n)\tp$$

This is a <em>system of algebraic equations</em>,

$$ u^n - \Delta t\,f(u^n,t_n) - u^{n-1}=0,$$

or written out

$$
\begin{align*}
u_0^n - \Delta t\, f_0(u^n,t_n) - u_0^{n-1} &= 0,\\ 
&\vdots\\ 
u_N^n - \Delta t\, f_N(u^n,t_n) - u_N^{n-1} &= 0\tp
\end{align*}
$$

<h3 id="___sec20">Example </h3>

<p>
We shall address the \( 2\times 2 \) ODE system for
oscillations of a pendulum
subject to gravity and air drag. The system can be written as

$$
\begin{align}
\dot\omega &= -\sin\theta -\beta \omega |\omega|,
\tag{14}\\ 
\dot\theta &= \omega,
\tag{15}
\end{align}
$$

where \( \beta \) is a dimensionless parameter (this is the scaled, dimensionless
version of the original, physical model). The unknown components of the
system are the
angle \( \theta(t) \) and the angular velocity \( \omega(t) \).
We introduce \( u_0=\omega \) and \( u_1=\theta \), which leads to

$$
\begin{align*}
u_0^{\prime} = f_0(u,t) &= -\sin u_1 - \beta u_0|u_0|,\\ 
u_1^{\prime} = f_1(u,t) &= u_0\tp
\end{align*}
$$

A Crank-Nicolson scheme reads

$$
\begin{align}
\frac{u_0^{n+1}-u_0^{n}}{\Delta t} &= -\sin u_1^{n+\frac{1}{2}}
- \beta u_0^{n+\frac{1}{2}}|u_0^{n+\frac{1}{2}}|\nonumber\\ 
& \approx -\sin\left(\frac{1}{2}(u_1^{n+1} + u_1n)\right)
- \beta\frac{1}{4} (u_0^{n+1} + u_0^n)|u_0^{n+1}+u_0^n|,
\tag{16}\\ 
\frac{u_1^{n+1}-u_1^n}{\Delta t} &= u_0^{n+\frac{1}{2}}\approx
\frac{1}{2} (u_0^{n+1}+u_0^n)\tp
\tag{17}
\end{align}
$$

This is a <em>coupled system</em> of two nonlinear algebraic equations
in two unknowns \( u_0^{n+1} \) and \( u_1^{n+1} \).

<p>
Using the notation \( u_0 \) and \( u_1 \) for the unknowns \( u_0^{n+1} \) and
\( u_1^{n+1} \) in this system, writing \( u_0^{(1)} \) and
\( u_1^{(1)} \) for the previous values \( u_0^n \) and \( u_1^n \), multiplying
by \( \Delta t \) and moving the terms to the left-hand sides, gives

$$
\begin{align}
u_0 - u_0^{(1)} + \Delta t\,\sin\left(\frac{1}{2}(u_1 + u_1^{(1)})\right)
+ \frac{1}{4}\Delta t\beta (u_0 + u_0^{(1)})|u_0 + u_0^{(1)}| &=0,
\tag{18}\\ 
u_1 - u_1^{(1)} -\frac{1}{2}\Delta t(u_0 + u_0^{(1)}) &=0\tp
\tag{19}
\end{align}
$$

Obviously, we have a need for solving systems of nonlinear algebraic
equations, which is the topic of the next section.

<p>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pager">
  <li class="previous">
    <a href="._nonlin000.html">&larr; Prev</a>
  </li>
  <li class="next">
    <a href="._nonlin002.html">Next &rarr;</a>
  </li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="http://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="http://..."><img width="250" align=right src="http://..."></a>
</footer>
-->


</body>
</html>
    

